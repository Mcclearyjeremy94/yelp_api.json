{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a16df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Additional Imports\n",
    "import os, json, math, time\n",
    "from yelpapi import YelpAPI\n",
    "from tqdm.notebook import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978c0ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Credentials\n",
    "with open('/Users/alisonwilliams/Documents/.secret/yelp_api.json') as f:   #use your path here!\n",
    "    login = json.load(f)\n",
    "# Instantiate YelpAPI Variable\n",
    "yelp_api = YelpAPI(login['api-key'], timeout_s=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc914b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our API call parameters \n",
    "LOCATION = 'Seattle'\n",
    "TERM = 'Sushi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "459f7236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/results_in_progress_wa_sushi.json'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying JSON_FILE filename (can include a folder)\n",
    "# include the search terms in the filename\n",
    "JSON_FILE_sushi = \"Data/results_in_progress_wa_sushi.json\"\n",
    "JSON_FILE_sushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "427ecf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Data/results_in_progress_wa_sushi.json already exists.\n"
     ]
    }
   ],
   "source": [
    "## Check if JSON_FILE exists\n",
    "file_exists = os.path.isfile(JSON_FILE_sushi)\n",
    "## If it does not exist: \n",
    "if file_exists == False:\n",
    "    \n",
    "    ## CREATE ANY NEEDED FOLDERS\n",
    "    # Get the Folder Name only\n",
    "    folder = os.path.dirname(JSON_FILE_sushi)\n",
    "    ## If JSON_FILE included a folder:\n",
    "    if len(folder)>0:\n",
    "        # create the folder\n",
    "        os.makedirs(folder,exist_ok=True)\n",
    "        \n",
    "        \n",
    "    ## INFORM USER AND SAVE EMPTY LIST\n",
    "    print(f'[i] {JSON_FILE_sushi} not found. Saving empty list to file.')\n",
    "    \n",
    "    \n",
    "    # save an empty list\n",
    "    with open(JSON_FILE_sushi,'w') as f:\n",
    "        json.dump([],f)  \n",
    "# If it exists, inform user\n",
    "else:\n",
    "    print(f\"[i] {JSON_FILE_sushi} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40b03b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0 previous results found.\n"
     ]
    }
   ],
   "source": [
    "## Load previous results and use len of results for offset\n",
    "with open(JSON_FILE_sushi,'r') as f:\n",
    "    previous_results = json.load(f)\n",
    "    \n",
    "## set offset based on previous results\n",
    "n_results = len(previous_results)\n",
    "print(f'- {n_results} previous results found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83eacf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['businesses', 'total', 'region'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location=LOCATION,\n",
    "                                term=TERM,\n",
    "                               offset=n_results)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d66c665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many results total?\n",
    "total_results = results['total']\n",
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3778a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many did we get the details for?\n",
    "results_per_page = len(results['businesses'])\n",
    "results_per_page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97563269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import additional packages for controlling our loop\n",
    "import time, math\n",
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil((results['total']-n_results)/ results_per_page)\n",
    "n_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eedba8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join new results with old list with extend and save to file\n",
    "previous_results.extend(results['businesses'])  \n",
    "with open(JSON_FILE_sushi,'w') as f:\n",
    "     json.dump(previous_results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eba95083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54469385103e478ea53c74af47ae7689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "import time\n",
    "for i in tqdm_notebook(range(n_pages)):\n",
    "    # adds 200 ms pause\n",
    "    time.sleep(.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "264e044d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21359ec13fe4dc185d8588924b829ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    \n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE_sushi, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results for to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    with open(JSON_FILE_sushi,'w') as f:\n",
    "        json.dump(previous_results,f)\n",
    "    \n",
    "    # add a 200ms pause\n",
    "    time.sleep(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f94539d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a813858b2b43388765a1b5767f0ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    \n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE_sushi, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results for to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    \n",
    "    if (n_results + results_per_page) > 1000:\n",
    "        print('Exceeded 1000 api calls. Stopping loop.')\n",
    "        break\n",
    "    \n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    # display(previous_results)\n",
    "    with open(JSON_FILE_sushi,'w') as f:\n",
    "        json.dump(previous_results,f)\n",
    "    \n",
    "    time.sleep(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final results\n",
    "final_df = pd.read_json(JSON_FILE_sushi)\n",
    "display(final_df.head(), final_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate results\n",
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a30051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate ID's \n",
    "final_df.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop duplicate ids and confirm there are no more duplicates\n",
    "final_df = final_df.drop_duplicates(subset='id')\n",
    "final_df.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final results to a compressed csv\n",
    "final_df.to_csv('Data/final_results_.csv.gz', compression='gzip',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
